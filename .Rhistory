<<<<<<< HEAD
,date_var = "DATE" # date format must be "2020-01-01"
,dep_var = "revenue" # there should be only one dependent variable
,dep_var_type = "revenue" # "revenue" or "conversion"
# "trend","season", "weekday", "holiday" are provided and case-sensitive.
# Recommended to at least keep Trend & Holidays
,prophet_vars = c("trend", "season", "holiday")
# c("default", "positive", and "negative"). Recommend as default.
# Must be same length as prophet_vars
,prophet_signs = c("default","default", "default")
# only one country allowed once. Including national holidays for 59 countries,
# whose list can be found on our githut guide
,prophet_country = "DE"
# typically competitors, price & promotion, temperature,  unemployment rate etc
,context_vars = c("competitor_sales_B", "events")
# c("default", "positive", and "negative"), control the signs of coefficients for baseline variables
,context_signs = c("default", "default")
# c("tv_S"	,"ooh_S",	"print_S"	,"facebook_I", "facebook_S"	,"search_clicks_P"	,"search_S").
# We recommend to use media exposure metrics like impressions, GRP etc for the model.
# If not applicable, use spend instead
,paid_media_vars = c("tv_S","ooh_S"	,	"print_S"	,"facebook_I"	,"search_clicks_P")
# c("default", "positive", and "negative"). must have same length as paid_media_vars.
# control the signs of coefficients for media variables
,paid_media_signs = c("positive", "positive","positive", "positive", "positive")
# spends must have same order and same length as paid_media_vars
,paid_media_spends = c("tv_S","ooh_S",	"print_S"	,"facebook_S"	,"search_S")
,organic_vars = c("newsletter")
,organic_signs = c("positive") # must have same length as organic_vars
,factor_vars = c("events") # specify which variables in context_vars and organic_vars are factorial
##############################
#### set model parameters ####
## set cores for parallel computing
,cores = 6 # I am using 6 cores from 8 on my local machine. Use detectCores() to find out cores
## set rolling window start
,window_start = "2016-11-23"
,window_end = "2018-08-22"
## set model core features
# Weibull is more flexible, yet has one more parameter and thus takes longer
,adstock = "geometric" # geometric or weibull
,iterations = 100  # number of allowed iterations per trial. 500 is recommended
# selected algorithm for Nevergrad, the gradient-free optimisation library
# https://facebookresearch.github.io/nevergrad/index.html
,nevergrad_algo = "TwoPointsDE"
# 40 is recommended without calibration, 100 with calibration.
,trials = 2 # number of allowed iterations per trial
## Time estimation: with geometric adstock, 2000 iterations * 5 trials and 6 cores,
# it takes about 30 minutes. Weibull takes at least twice as much time.
#,hyperparameters = hyperparameters
# ,calibration_input = data.table(channel = c("facebook_I",  "tv_S", "facebook_I"),
#                        liftStartDate = as.Date(c("2018-05-01", "2017-11-27", "2018-07-01")),
#                        liftEndDate = as.Date(c("2018-06-10", "2017-12-03", "2018-07-20")),
#                        liftAbs = c(400000, 300000, 200000))
)
library(Robyn)
library(Robyn)
InputCollect <- robyn_inputs(
dt_input = dt_simulated_weekly
,dt_holidays = dt_prophet_holidays
#######################
#### set variables ####
,date_var = "DATE" # date format must be "2020-01-01"
,dep_var = "revenue" # there should be only one dependent variable
,dep_var_type = "revenue" # "revenue" or "conversion"
# "trend","season", "weekday", "holiday" are provided and case-sensitive.
# Recommended to at least keep Trend & Holidays
,prophet_vars = c("trend", "season", "holiday")
# c("default", "positive", and "negative"). Recommend as default.
# Must be same length as prophet_vars
,prophet_signs = c("default","default", "default")
# only one country allowed once. Including national holidays for 59 countries,
# whose list can be found on our githut guide
,prophet_country = "DE"
# typically competitors, price & promotion, temperature,  unemployment rate etc
,context_vars = c("competitor_sales_B", "events")
# c("default", "positive", and "negative"), control the signs of coefficients for baseline variables
,context_signs = c("default", "default")
# c("tv_S"	,"ooh_S",	"print_S"	,"facebook_I", "facebook_S"	,"search_clicks_P"	,"search_S").
# We recommend to use media exposure metrics like impressions, GRP etc for the model.
# If not applicable, use spend instead
,paid_media_vars = c("tv_S","ooh_S"	,	"print_S"	,"facebook_I"	,"search_clicks_P")
# c("default", "positive", and "negative"). must have same length as paid_media_vars.
# control the signs of coefficients for media variables
,paid_media_signs = c("positive", "positive","positive", "positive", "positive")
# spends must have same order and same length as paid_media_vars
,paid_media_spends = c("tv_S","ooh_S",	"print_S"	,"facebook_S"	,"search_S")
,organic_vars = c("newsletter")
,organic_signs = c("positive") # must have same length as organic_vars
,factor_vars = c("events") # specify which variables in context_vars and organic_vars are factorial
##############################
#### set model parameters ####
## set cores for parallel computing
,cores = 6 # I am using 6 cores from 8 on my local machine. Use detectCores() to find out cores
## set rolling window start
,window_start = "2016-11-23"
,window_end = "2018-08-22"
## set model core features
# Weibull is more flexible, yet has one more parameter and thus takes longer
,adstock = "geometric" # geometric or weibull
,iterations = 100  # number of allowed iterations per trial. 500 is recommended
# selected algorithm for Nevergrad, the gradient-free optimisation library
# https://facebookresearch.github.io/nevergrad/index.html
,nevergrad_algo = "TwoPointsDE"
# 40 is recommended without calibration, 100 with calibration.
,trials = 2 # number of allowed iterations per trial
## Time estimation: with geometric adstock, 2000 iterations * 5 trials and 6 cores,
# it takes about 30 minutes. Weibull takes at least twice as much time.
#,hyperparameters = hyperparameters
# ,calibration_input = data.table(channel = c("facebook_I",  "tv_S", "facebook_I"),
#                        liftStartDate = as.Date(c("2018-05-01", "2017-11-27", "2018-07-01")),
#                        liftEndDate = as.Date(c("2018-06-10", "2017-12-03", "2018-07-20")),
#                        liftAbs = c(400000, 300000, 200000))
)
# helper plots: set plot to TRUE for transformation examples:
# adstock transformation example plot, helping you understand geometric/theta and weibull/shape/scale transformation
plot_adstock(FALSE)
# s-curve transformation example plot, helping you understand hill/alpha/gamma transformatio
plot_saturation(FALSE)
hyper_names(adstock = InputCollect$adstock, all_media = InputCollect$all_media)
hyperparameters <- list(
facebook_I_alphas = c(0.5, 3) # example bounds for alpha
,facebook_I_gammas = c(0.3, 1) # example bounds for gamma
,facebook_I_thetas = c(0, 0.3) # example bounds for theta
#,facebook_I_shapes = c(0.0001, 2) # example bounds for shape
#,facebook_I_scales = c(0, 0.1) # example bounds for scale
,print_S_alphas = c(0.5, 3)
,print_S_gammas = c(0.3, 1)
,print_S_thetas = c(0.1, 0.4)
#,print_S_shapes = c(0.0001, 2)
#,print_S_scales = c(0, 0.1)
,tv_S_alphas = c(0.5, 3)
,tv_S_gammas = c(0.3, 1)
,tv_S_thetas = c(0.3, 0.8)
#,tv_S_shapes = c(0.0001, 2)
#,tv_S_scales= c(0, 0.1)
,search_clicks_P_alphas = c(0.5, 3)
,search_clicks_P_gammas = c(0.3, 1)
,search_clicks_P_thetas = c(0, 0.3)
#,search_clicks_P_shapes = c(0.0001, 2)
#,search_clicks_P_scales = c(0, 0.1)
,ooh_S_alphas = c(0.5, 3)
,ooh_S_gammas = c(0.3, 1)
,ooh_S_thetas = c(0.1, 0.4)
#,ooh_S_shapes = c(0.0001, 2)
#,ooh_S_scales = c(0, 0.1)
,newsletter_alphas = c(0.5, 3)
,newsletter_gammas = c(0.3, 1)
,newsletter_thetas = c(0.1, 0.4)
#,newsletter_shapes = c(0.0001, 2)
#,newsletter_scales = c(0, 0.1)
)
InputCollect <- robyn_inputs(InputCollect = InputCollect
, hyperparameters = hyperparameters)
?add_regressor
devtools::document()
devtools::document()
library(Robyn)
InputCollect <- robyn_inputs(InputCollect = InputCollect
, hyperparameters = hyperparameters)
OutputCollect <- robyn_run(InputCollect = InputCollect
, plot_folder = robyn_object
, pareto_fronts = 1
, plot_pareto = TRUE)
?registerDoFuture
??registerDoFuture
library(Robyn)
OutputCollect <- robyn_run(InputCollect = InputCollect
, plot_folder = robyn_object
, pareto_fronts = 1
, plot_pareto = TRUE)
library(Robyn)
## Install and load libraries
library(Robyn) # devtools::install_github("facebookexperimental/Robyn@package_test")
## Check simulatetd dataset or load your own dataset
data("dt_simulated_weekly")
head(dt_simulated_weekly)
## Check holidays from Prophet
# 59 countries included. If your country is not included, please manually add it.
# Tipp: any events can be added into this table, school break, events etc.
data("dt_prophet_holidays")
head(dt_prophet_holidays)
## Set robyn_object. It must has extension .RData. The object name can be different than Robyn
robyn_object <- "~/Desktop/Robyn.RData"
InputCollect <- robyn_inputs(
dt_input = dt_simulated_weekly
,dt_holidays = dt_prophet_holidays
=======
library(Robyn)
library(Robyn)
## load scripts
script_path = substr(rstudioapi::getActiveDocumentContext()$path, start = 1, stop = max(gregexpr("/", rstudioapi::getActiveDocumentContext()$path)[[1]]))
source(paste(script_path, "fb_robyn.func.R", sep=""))
source(paste(script_path, "fb_robyn.optm.R", sep=""))
## load libraries
load_libs()
## load input data & holiday.
## Please note the simulated dataset includes new variables "newsletter" and "events" now to demonstrate usage of factor_vars and organic_vars
dt_input <- fread(paste0(script_path, "de_simulated_data.csv"))
dt_holidays <- fread(paste0(script_path, "holidays.csv"))
## IMPORTANT: robyn_object must has extension .RData. The object name can be changed.
robyn_object <- "/Users/gufengzhou/Documents/robyn_dev_output/Robyn.RData"
registerDoSEQ(); availableCores()
InputCollect <- robyn_inputs(dt_input = dt_input
,dt_holidays = dt_holidays
>>>>>>> de977b5b6580c2d75a803a72d7657985958f39ed
#######################
#### set variables ####
,date_var = "DATE" # date format must be "2020-01-01"
,dep_var = "revenue" # there should be only one dependent variable
,dep_var_type = "revenue" # "revenue" or "conversion"
,prophet_vars = c("trend", "season", "holiday") # "trend","season", "weekday", "holiday" are provided and case-sensitive. Recommended to at least keep Trend & Holidays
,prophet_signs = c("default","default", "default") # c("default", "positive", and "negative"). Recommend as default. Must be same length as prophet_vars
,prophet_country = "DE" # only one country allowed once. Including national holidays for 59 countries, whose list can be found on our githut guide
,context_vars = c("competitor_sales_B", "events") # typically competitors, price & promotion, temperature,  unemployment rate etc
,context_signs = c("default", "default") # c("default", "positive", and "negative"), control the signs of coefficients for baseline variables
,paid_media_vars = c("tv_S","ooh_S"	,	"print_S"	,"facebook_I"	,"search_clicks_P") # c("tv_S"	,"ooh_S",	"print_S"	,"facebook_I", "facebook_S"	,"search_clicks_P"	,"search_S") we recommend to use media exposure metrics like impressions, GRP etc for the model. If not applicable, use spend instead
,paid_media_signs = c("positive", "positive","positive", "positive", "positive") # c("default", "positive", and "negative"). must have same length as paid_media_vars. control the signs of coefficients for media variables
,paid_media_spends = c("tv_S","ooh_S",	"print_S"	,"facebook_S"	,"search_S") # spends must have same order and same length as paid_media_vars
,organic_vars = c("newsletter")
,organic_signs = c("positive") # must have same length as organic_vars
,factor_vars = c("events") # specify which variables in context_vars and organic_vars are factorial
##############################
#### set model parameters ####
## set cores for parallel computing
,cores = 6 # I am using 6 cores from 8 on my local machine. Use detectCores() to find out cores
## set rolling window start
,window_start = "2016-11-23"
,window_end = "2018-08-22"
## set model core features
,adstock = "geometric" # geometric or weibull. weibull is more flexible, yet has one more parameter and thus takes longer
,iterations = 200  # number of allowed iterations per trial. 500 is recommended
,nevergrad_algo = "TwoPointsDE" # selected algorithm for Nevergrad, the gradient-free optimisation library https://facebookresearch.github.io/nevergrad/index.html
,trials = 2 # number of allowed iterations per trial. 40 is recommended without calibration, 100 with calibration.
## Time estimation: with geometric adstock, 500 iterations * 40 trials and 6 cores, it takes less than 1 hour. Weibull takes at least twice as much time.
#,hyperparameters = hyperparameters
# ,calibration_input = data.table(channel = c("facebook_I",  "tv_S", "facebook_I"),
#                        liftStartDate = as.Date(c("2018-05-01", "2017-11-27", "2018-07-01")),
#                        liftEndDate = as.Date(c("2018-06-10", "2017-12-03", "2018-07-20")),
#                        liftAbs = c(400000, 300000, 200000))
)
<<<<<<< HEAD
# helper plots: set plot to TRUE for transformation examples:
# adstock transformation example plot, helping you understand geometric/theta and weibull/shape/scale transformation
plot_adstock(FALSE)
# s-curve transformation example plot, helping you understand hill/alpha/gamma transformatio
plot_saturation(FALSE)
=======
# helper plots: set plot to TRUE for transformation examples
plot_adstock(FALSE) # adstock transformation example plot, helping you understand geometric/theta and weibull/shape/scale transformation
plot_saturation(FALSE) # s-curve transformation example plot, helping you understand hill/alpha/gamma transformatio
>>>>>>> de977b5b6580c2d75a803a72d7657985958f39ed
hyper_names(adstock = InputCollect$adstock, all_media = InputCollect$all_media)
hyperparameters <- list(
facebook_I_alphas = c(0.5, 3) # example bounds for alpha
,facebook_I_gammas = c(0.3, 1) # example bounds for gamma
,facebook_I_thetas = c(0, 0.3) # example bounds for theta
#,facebook_I_shapes = c(0.0001, 2) # example bounds for shape
#,facebook_I_scales = c(0, 0.1) # example bounds for scale
,print_S_alphas = c(0.5, 3)
,print_S_gammas = c(0.3, 1)
,print_S_thetas = c(0.1, 0.4)
#,print_S_shapes = c(0.0001, 2)
#,print_S_scales = c(0, 0.1)
,tv_S_alphas = c(0.5, 3)
,tv_S_gammas = c(0.3, 1)
,tv_S_thetas = c(0.3, 0.8)
#,tv_S_shapes = c(0.0001, 2)
#,tv_S_scales= c(0, 0.1)
,search_clicks_P_alphas = c(0.5, 3)
,search_clicks_P_gammas = c(0.3, 1)
,search_clicks_P_thetas = c(0, 0.3)
#,search_clicks_P_shapes = c(0.0001, 2)
#,search_clicks_P_scales = c(0, 0.1)
,ooh_S_alphas = c(0.5, 3)
,ooh_S_gammas = c(0.3, 1)
,ooh_S_thetas = c(0.1, 0.4)
#,ooh_S_shapes = c(0.0001, 2)
#,ooh_S_scales = c(0, 0.1)
,newsletter_alphas = c(0.5, 3)
,newsletter_gammas = c(0.3, 1)
,newsletter_thetas = c(0.1, 0.4)
#,newsletter_shapes = c(0.0001, 2)
#,newsletter_scales = c(0, 0.1)
)
InputCollect <- robyn_inputs(InputCollect = InputCollect
, hyperparameters = hyperparameters)
OutputCollect <- robyn_run(InputCollect = InputCollect
, plot_folder = robyn_object
, pareto_fronts = 1
<<<<<<< HEAD
, plot_pareto = TRUE)
?doFuture
?registerDoFuture
??registerDoFuture
install.packages("v")
install.packages("doFuture")
install.packages("doFuture")
library(doFuture)
doFuture::registerDoFuture()
devtools::document()
devtools::document()
library(Robyn)
OutputCollect <- robyn_run(InputCollect = InputCollect
, plot_folder = robyn_object
, pareto_fronts = 1
, plot_pareto = TRUE)
OutputCollect$allSolutions
select_model <- "2_12_1"
robyn_save(robyn_object = robyn_object
, select_model = select_model
, InputCollect = InputCollect
, OutputCollect = OutputCollect)
# Check media summary for selected model
OutputCollect$xDecompAgg[solID == select_model & !is.na(mean_spend),
.(rn, coef,mean_spend, mean_response, roi_mean, total_spend,
total_response = xDecompAgg, roi_total, solID)]
AllocatorCollect <- robyn_allocator(
InputCollect = InputCollect
,OutputCollect = OutputCollect
# input one of the model IDs in model_output_collect$allSolutions to get optimization result
,select_model = select_model
,optim_algo = "SLSQP_AUGLAG" # "MMA_AUGLAG", "SLSQP_AUGLAG"
,scenario = "max_historical_response" # c(max_historical_response, max_response_expected_spend)
# specify future spend volume. only applies when scenario = "max_response_expected_spend"
#,expected_spend = 100000
# specify period for the future spend volume in days. Only applies when scenario = "max_response_expected_spend"
#,expected_spend_days = 90
# must be between 0.01-1 and has same length and order as paid_media_vars
,channel_constr_low = c(0.7, 0.7, 0.7, 0.7, 0.7)
# not recommended to 'exaggerate' upper bounds.
# 1.5 means channel budget can increase to 150% of current level
,channel_constr_up = c(1.2, 1.5, 1.5, 1.5, 1.5)
)
Robyn <- robyn_refresh(robyn_object = robyn_object # the location of your Robyn.RData object
, dt_input = dt_simulated_weekly
, dt_holidays = dt_prophet_holidays
# refresh_steps = 4 means refresh model's rolling window will move forward 4 weeks
, refresh_steps = 13
# "auto" means the refresh function will move forward until no more data available
, refresh_mode = "manual"
, refresh_iters = 150 # iteration for refresh
, refresh_trials = 1 # trial for refresh
)
AllocatorCollect <- robyn_allocator(
robyn_object = robyn_object
# , select_run
, optim_algo = "SLSQP_AUGLAG" # "MMA_AUGLAG", "SLSQP_AUGLAG"
, scenario = "max_historical_response" # c(max_historical_response, max_response_expected_spend)
# specify future spend volume. only applies when scenario = "max_response_expected_spend"
#, expected_spend = 100000
# specify period for the future spend volumne in days. only applies when scenario = "max_response_expected_spend"
#, expected_spend_days = 90
# must be between 0.01-1 and has same length and order as paid_media_vars
, channel_constr_low = c(0.7, 0.7, 0.7, 0.7, 0.7)
# not recommended to 'exaggerate' upper bounds. 1.5 means channel budget can increase to 150% of current level
, channel_constr_up = c(1.2, 1.5, 1.5, 1.5, 1.5)
)
# get response for 80k
Spend1 <- 80000
Response1 <- robyn_response(robyn_object = robyn_object
#, select_run = 1 # 2 means the sedond refresh model. 0 means the initial model
, paid_media_var = "search_clicks_P"
, Spend = Spend1)
Response1/Spend1 # ROI for search 80k
# get response for 81k
Spend2 <- Spend1+1000
Response2 <- robyn_response(robyn_object = robyn_object
#, select_run = 1
, paid_media_var = "search_clicks_P"
, Spend = Spend2)
Response2/Spend2 # ROI for search 81k
# marginal ROI of next 1000$ from 80k spend level for search
(Response2-Response1)/(Spend2-Spend1)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
detectCores()
?wday
?day
day(Sys.Date())
lubridate::day(Sys.Date())
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
?detectCores
?weekday
weekday
devtools::document()
?multicoremulticore
multicore?
?multicore
?multicore
?plan
devtools::document()
InputCollect$calibration_input
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::install_github("facebookexperimental/Robyn@package_test")
## Install and load libraries
library(Robyn) # devtools::install_github("facebookexperimental/Robyn@package_test")
## Check simulated dataset or load your own dataset
=======
, plot_pareto = F)
library(Robyn)
################################################################
#### Step 1: load data
# rm(list = ls())
## Check simulatetd dataset or load your own dataset
>>>>>>> de977b5b6580c2d75a803a72d7657985958f39ed
data("dt_simulated_weekly")
head(dt_simulated_weekly)
## Check holidays from Prophet
# 59 countries included. If your country is not included, please manually add it.
# Tipp: any events can be added into this table, school break, events etc.
data("dt_prophet_holidays")
head(dt_prophet_holidays)
<<<<<<< HEAD
## Set robyn_object. It must have extension .RData. The object name can be different than Robyn:
robyn_object <- "~/Desktop/Robyn.RData"
InputCollect <- robyn_inputs(
dt_input = dt_simulated_weekly
=======
## Set robyn_object. It must has extension .RData. The object name can be different than Robyn
robyn_object <- "/Users/gufengzhou/Documents/robyn_dev_output/Robyn.RData"
################################################################
#### Step 2: define model variables & parameters
InputCollect <- robyn_inputs(dt_input = dt_simulated_weekly
>>>>>>> de977b5b6580c2d75a803a72d7657985958f39ed
,dt_holidays = dt_prophet_holidays
#######################
#### set variables ####
,date_var = "DATE" # date format must be "2020-01-01"
,dep_var = "revenue" # there should be only one dependent variable
,dep_var_type = "revenue" # "revenue" or "conversion"
,prophet_vars = c("trend", "season", "holiday") # "trend","season", "weekday", "holiday" are provided and case-sensitive. Recommended to at least keep Trend & Holidays
,prophet_signs = c("default","default", "default") # c("default", "positive", and "negative"). Recommend as default. Must be same length as prophet_vars
,prophet_country = "DE" # only one country allowed once. Including national holidays for 59 countries, whose list can be found on our githut guide
,context_vars = c("competitor_sales_B", "events") # typically competitors, price & promotion, temperature,  unemployment rate etc
,context_signs = c("default", "default") # c("default", "positive", and "negative"), control the signs of coefficients for baseline variables
,paid_media_vars = c("tv_S","ooh_S"	,	"print_S"	,"facebook_I"	,"search_clicks_P") # c("tv_S"	,"ooh_S",	"print_S"	,"facebook_I", "facebook_S"	,"search_clicks_P"	,"search_S") we recommend to use media exposure metrics like impressions, GRP etc for the model. If not applicable, use spend instead
,paid_media_signs = c("positive", "positive","positive", "positive", "positive") # c("default", "positive", and "negative"). must have same length as paid_media_vars. control the signs of coefficients for media variables
,paid_media_spends = c("tv_S","ooh_S",	"print_S"	,"facebook_S"	,"search_S") # spends must have same order and same length as paid_media_vars
,organic_vars = c("newsletter")
,organic_signs = c("positive") # must have same length as organic_vars
,factor_vars = c("events") # specify which variables in context_vars and organic_vars are factorial
##############################
#### set model parameters ####
## set cores for parallel computing
,cores = 6 # I am using 6 cores from 8 on my local machine. Use detectCores() to find out cores
## set rolling window start
,window_start = "2016-11-23"
,window_end = "2018-08-22"
## set model core features
,adstock = "geometric" # geometric or weibull. weibull is more flexible, yet has one more parameter and thus takes longer
,iterations = 100  # number of allowed iterations per trial. 500 is recommended
<<<<<<< HEAD
# selected algorithm for Nevergrad, the gradient-free optimization library
# https://facebookresearch.github.io/nevergrad/index.html
,nevergrad_algo = "TwoPointsDE"
# 40 is recommended without calibration, 100 with calibration.
,trials = 2 # number of allowed iterations per trial
## Time estimation: with geometric adstock, 2000 iterations * 5 trials and 6 cores,
# it takes about 30 minutes. Weibull takes at least twice as much time.
=======
,nevergrad_algo = "TwoPointsDE" # selected algorithm for Nevergrad, the gradient-free optimisation library https://facebookresearch.github.io/nevergrad/index.html
,trials = 2 # number of allowed iterations per trial. 40 is recommended without calibration, 100 with calibration.
## Time estimation: with geometric adstock, 2000 iterations * 5 trials and 6 cores, it takes about 30 minutes. Weibull takes at least twice as much time.
>>>>>>> de977b5b6580c2d75a803a72d7657985958f39ed
#,hyperparameters = hyperparameters
# ,calibration_input = data.table(channel = c("facebook_I",  "tv_S", "facebook_I"),
#                        liftStartDate = as.Date(c("2018-05-01", "2017-11-27", "2018-07-01")),
#                        liftEndDate = as.Date(c("2018-06-10", "2017-12-03", "2018-07-20")),
#                        liftAbs = c(400000, 300000, 200000))
)
################################################################
#### Step 3: define and add hyperparameters
## Guide to setup hyperparameters
## 1. get correct hyperparameter names:
# all variables in paid_media_vars or organic_vars require hyperprameter and will be transformed by adstock & saturation
# difference between paid_media_vars and organic_vars is that paid_media_vars has spend that needs to be specified in paid_media_spends specifically
# run hyper_names() to get correct hyperparameter names. all names in hyperparameters must equal names from hyper_names(), case sensitive
## 2. get guidance for setting hyperparameter bounds:
# For geometric adstock, use theta, alpha & gamma. For weibull adstock, use shape, scale, alpha, gamma
# theta: In geometric adstock, theta is decay rate. guideline for usual media genre: TV c(0.3, 0.8), OOH/Print/Radio c(0.1, 0.4), digital c(0, 0.3)
# shape: In weibull adstock, shape controls the decay shape. Recommended c(0.0001, 2). The larger, the more S-shape. The smaller, the more L-shape
# scale: In weibull adstock, scale controls the decay inflexion point. Very conservative recommended bounce c(0, 0.1), becausee scale can increase adstocking half-life greaetly
# alpha: In s-curve transformation with hill function, alpha controls the shape between exponential and s-shape. Recommended c(0.5, 3). The larger the alpha, the more S-shape. The smaller, the more C-shape
# gamma: In s-curve transformation with hill function, gamma controls the inflexion point. Recommended bounce c(0.3, 1). The larger the gamma, the later the inflection point in the response curve
# helper plots: set plot to TRUE for transformation examples
plot_adstock(FALSE) # adstock transformation example plot, helping you understand geometric/theta and weibull/shape/scale transformation
plot_saturation(FALSE) # s-curve transformation example plot, helping you understand hill/alpha/gamma transformatio
## 3. set each hyperparameter bounds. They either contains two values e.g. c(0, 0.5), or only one value (in which case you've "fixed" that hyperparameter)
hyper_names(adstock = InputCollect$adstock, all_media = InputCollect$all_media)
hyperparameters <- list(
facebook_I_alphas = c(0.5, 3) # example bounds for alpha
,facebook_I_gammas = c(0.3, 1) # example bounds for gamma
,facebook_I_thetas = c(0, 0.3) # example bounds for theta
#,facebook_I_shapes = c(0.0001, 2) # example bounds for shape
#,facebook_I_scales = c(0, 0.1) # example bounds for scale
,print_S_alphas = c(0.5, 3)
,print_S_gammas = c(0.3, 1)
,print_S_thetas = c(0.1, 0.4)
#,print_S_shapes = c(0.0001, 2)
#,print_S_scales = c(0, 0.1)
,tv_S_alphas = c(0.5, 3)
,tv_S_gammas = c(0.3, 1)
,tv_S_thetas = c(0.3, 0.8)
#,tv_S_shapes = c(0.0001, 2)
#,tv_S_scales= c(0, 0.1)
,search_clicks_P_alphas = c(0.5, 3)
,search_clicks_P_gammas = c(0.3, 1)
,search_clicks_P_thetas = c(0, 0.3)
#,search_clicks_P_shapes = c(0.0001, 2)
#,search_clicks_P_scales = c(0, 0.1)
,ooh_S_alphas = c(0.5, 3)
,ooh_S_gammas = c(0.3, 1)
,ooh_S_thetas = c(0.1, 0.4)
#,ooh_S_shapes = c(0.0001, 2)
#,ooh_S_scales = c(0, 0.1)
,newsletter_alphas = c(0.5, 3)
,newsletter_gammas = c(0.3, 1)
,newsletter_thetas = c(0.1, 0.4)
#,newsletter_shapes = c(0.0001, 2)
#,newsletter_scales = c(0, 0.1)
)
## Add hyperparameters intu robyn_inputs()
InputCollect <- robyn_inputs(InputCollect = InputCollect
, hyperparameters = hyperparameters)
<<<<<<< HEAD
devtools::document()
devtools::document()
devtools::document()
devtools::document()
=======
## NOTE: The example above is to get InputCollect for the first time and done in 2 steps
## NOTE: If hyperparameters are set before, robyn_inputs() can be also done in 1 step by providing the hyperparameters parameter immediately
################################################################
#### Step 4: Build initial model
>>>>>>> de977b5b6580c2d75a803a72d7657985958f39ed
OutputCollect <- robyn_run(InputCollect = InputCollect
, plot_folder = robyn_object
, pareto_fronts = 1
, plot_pareto = TRUE)
devtools::install_github("facebookexperimental/Robyn@package_test")
## Install and load libraries
library(Robyn) # devtools::install_github("facebookexperimental/Robyn@package_test")
devtools::install_github("facebookexperimental/Robyn@package_test")
## Install and load libraries
library(Robyn) # devtools::install_github("facebookexperimental/Robyn@package_test")
################################################################
#### Step 1: load data
# rm(list = ls())
## Check simulatetd dataset or load your own dataset
data("dt_simulated_weekly")
head(dt_simulated_weekly)
## Check holidays from Prophet
# 59 countries included. If your country is not included, please manually add it.
# Tipp: any events can be added into this table, school break, events etc.
data("dt_prophet_holidays")
head(dt_prophet_holidays)
## Set robyn_object. It must has extension .RData. The object name can be different than Robyn
robyn_object <- "/Users/gufengzhou/Documents/robyn_dev_output/Robyn.RData"
InputCollect <- robyn_inputs(dt_input = dt_simulated_weekly
,dt_holidays = dt_prophet_holidays
#######################
#### set variables ####
,date_var = "DATE" # date format must be "2020-01-01"
,dep_var = "revenue" # there should be only one dependent variable
,dep_var_type = "revenue" # "revenue" or "conversion"
,prophet_vars = c("trend", "season", "holiday") # "trend","season", "weekday", "holiday" are provided and case-sensitive. Recommended to at least keep Trend & Holidays
,prophet_signs = c("default","default", "default") # c("default", "positive", and "negative"). Recommend as default. Must be same length as prophet_vars
,prophet_country = "DE" # only one country allowed once. Including national holidays for 59 countries, whose list can be found on our githut guide
,context_vars = c("competitor_sales_B", "events") # typically competitors, price & promotion, temperature,  unemployment rate etc
,context_signs = c("default", "default") # c("default", "positive", and "negative"), control the signs of coefficients for baseline variables
,paid_media_vars = c("tv_S","ooh_S"	,	"print_S"	,"facebook_I"	,"search_clicks_P") # c("tv_S"	,"ooh_S",	"print_S"	,"facebook_I", "facebook_S"	,"search_clicks_P"	,"search_S") we recommend to use media exposure metrics like impressions, GRP etc for the model. If not applicable, use spend instead
,paid_media_signs = c("positive", "positive","positive", "positive", "positive") # c("default", "positive", and "negative"). must have same length as paid_media_vars. control the signs of coefficients for media variables
,paid_media_spends = c("tv_S","ooh_S",	"print_S"	,"facebook_S"	,"search_S") # spends must have same order and same length as paid_media_vars
,organic_vars = c("newsletter")
,organic_signs = c("positive") # must have same length as organic_vars
,factor_vars = c("events") # specify which variables in context_vars and organic_vars are factorial
##############################
#### set model parameters ####
## set cores for parallel computing
,cores = 6 # I am using 6 cores from 8 on my local machine. Use detectCores() to find out cores
## set rolling window start
,window_start = "2016-11-23"
,window_end = "2018-08-22"
## set model core features
,adstock = "geometric" # geometric or weibull. weibull is more flexible, yet has one more parameter and thus takes longer
,iterations = 100  # number of allowed iterations per trial. 500 is recommended
,nevergrad_algo = "TwoPointsDE" # selected algorithm for Nevergrad, the gradient-free optimisation library https://facebookresearch.github.io/nevergrad/index.html
,trials = 2 # number of allowed iterations per trial. 40 is recommended without calibration, 100 with calibration.
## Time estimation: with geometric adstock, 2000 iterations * 5 trials and 6 cores, it takes about 30 minutes. Weibull takes at least twice as much time.
#,hyperparameters = hyperparameters
# ,calibration_input = data.table(channel = c("facebook_I",  "tv_S", "facebook_I"),
#                        liftStartDate = as.Date(c("2018-05-01", "2017-11-27", "2018-07-01")),
#                        liftEndDate = as.Date(c("2018-06-10", "2017-12-03", "2018-07-20")),
#                        liftAbs = c(400000, 300000, 200000))
)
# helper plots: set plot to TRUE for transformation examples
plot_adstock(FALSE) # adstock transformation example plot, helping you understand geometric/theta and weibull/shape/scale transformation
plot_saturation(FALSE) # s-curve transformation example plot, helping you understand hill/alpha/gamma transformatio
# helper plots: set plot to TRUE for transformation examples
plot_adstock(T) # adstock transformation example plot, helping you understand geometric/theta and weibull/shape/scale transformation
# helper plots: set plot to TRUE for transformation examples
plot_adstock(T) # adstock transformation example plot, helping you understand geometric/theta and weibull/shape/scale transformation
plot_saturation(T) # s-curve transformation example plot, helping you understand hill/alpha/gamma transformatio
